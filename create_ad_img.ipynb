{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4aff75-aba0-4a3e-bb0a-35618f934858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import foolbox as fb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db87da51-8ae7-4e4a-b5ad-7ae3f77a37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pandas.io.parsers import read_csv\n",
    "\n",
    "\n",
    "## Loading datasets\n",
    "file_path = 'train.pickle'\n",
    "training_file = 'train.pickle'\n",
    "validation_file='valid.pickle'\n",
    "testing_file = 'test.pickle'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "sign_names = read_csv(\"label_names.csv\").values[:, 1]\n",
    "\n",
    "#Separating features and labels\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1248e57-84f2-4654-9a0f-37c96fd63ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "# Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "# Number of validation examples\n",
    "n_validation = X_valid.shape[0]\n",
    "# Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "# What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape\n",
    "# Unique classes/labels there are in the dataset.\n",
    "classes, class_indices, class_counts  = np.unique(y_train, return_index=True, return_counts=True)\n",
    "n_classes = len(class_counts)\n",
    "\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6a3685-ab26-496c-bce3-cc06320f7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "## Shuffle the dataset\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78f72dc-f0c1-4d21-a229-1994ee4eb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB images to grayscale for the training set\n",
    "X_train_gray = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "\n",
    "# Convert RGB images to grayscale for the testing set\n",
    "X_test_gray  = np.sum(X_test/3, axis=3, keepdims=True)\n",
    "\n",
    "# Convert RGB images to grayscale for the validation set\n",
    "X_validation_gray  = np.sum(X_valid/3, axis=3, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46b79ff-d789-42e2-a657-02a16d4d10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training set of grayscale images\n",
    "X_train_gray_norm = (X_train_gray - 32) / 32\n",
    "\n",
    "# Normalize the test set of grayscale images\n",
    "X_test_gray_norm = (X_test_gray - 32) / 32\n",
    "\n",
    "# Normalize the validation set of grayscale images\n",
    "X_validation_gray_norm = (X_validation_gray - 32) / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "151bb1b7-4c0b-4111-ab04-13e814f31771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot Encoding the labels.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Store the original labels for future reference\n",
    "y_train_unchanged = y_train\n",
    "y_validation_unchanged = y_valid\n",
    "y_test_unchanged = y_test\n",
    "\n",
    "# Perform Onehot Encoding on the labels\n",
    "# Convert the labels from integer representation to binary matrix representation\n",
    "y_train = to_categorical(y_train)\n",
    "y_validation = to_categorical(y_valid)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5653e3a1-8722-40b3-a0dc-bb8969f563a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('Checkpoint_AlexNet_Epoch_50.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ef7516c-cfcd-4765-9091-46e79d669011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - accuracy: 0.8762 - loss: 0.5231\n",
      "Test Loss: 0.5332487225532532\n",
      "Test Accuracy: 0.8771971464157104\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_gray_norm, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55d123d3-8811-4c06-9b8e-ca37a846faac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nitiw\\anaconda3\\envs\\foolbox_evasion\\Lib\\site-packages\\foolbox\\models\\tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nitiw\\anaconda3\\envs\\foolbox_evasion\\Lib\\site-packages\\foolbox\\models\\tensorflow.py:13: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "`np.find_common_type` was removed in the NumPy 2.0 release. Use `numpy.promote_types` or `numpy.result_type` instead. To achieve semantics for the `scalar_types` argument, use `numpy.result_type` and pass the Python values `0`, `0.0`, or `0j`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m X_test_gray_norm_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(X_test_gray_norm, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Generate adversarial examples\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m adversarial_examples, perturbed_images, success \u001b[38;5;241m=\u001b[39m attack(fmodel, X_test_gray_norm_tensor, criterion\u001b[38;5;241m=\u001b[39mcriterion, epsilons\u001b[38;5;241m=\u001b[39mepsilon)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\foolbox_evasion\\Lib\\site-packages\\foolbox\\attacks\\base.py:289\u001b[0m, in \u001b[0;36mFixedEpsilonAttack.__call__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m# clip to epsilon because we don't really know what the attack returns;\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# alternatively, we could check if the perturbation is at most epsilon,\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# but then we would need to handle numerical violations;\u001b[39;00m\n\u001b[0;32m    288\u001b[0m xpc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39mclip_perturbation(x, xp, epsilon)\n\u001b[1;32m--> 289\u001b[0m is_adv \u001b[38;5;241m=\u001b[39m is_adversarial(xpc)\n\u001b[0;32m    291\u001b[0m xps\u001b[38;5;241m.\u001b[39mappend(xp)\n\u001b[0;32m    292\u001b[0m xpcs\u001b[38;5;241m.\u001b[39mappend(xpc)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\foolbox_evasion\\Lib\\site-packages\\foolbox\\attacks\\base.py:464\u001b[0m, in \u001b[0;36mget_is_adversarial.<locals>.is_adversarial\u001b[1;34m(perturbed)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_adversarial\u001b[39m(perturbed: ep\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ep\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    463\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(perturbed)\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m criterion(perturbed, outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\foolbox_evasion\\Lib\\site-packages\\foolbox\\criteria.py:117\u001b[0m, in \u001b[0;36mMisclassification.__call__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    115\u001b[0m classes \u001b[38;5;241m=\u001b[39m outputs_\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 117\u001b[0m is_adv \u001b[38;5;241m=\u001b[39m classes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restore_type(is_adv)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\foolbox_evasion\\Lib\\site-packages\\eagerpy\\tensor\\tensorflow.py:58\u001b[0m, in \u001b[0;36mcommon_dtype.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     57\u001b[0m numpy_dtypes \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mdtype(dtype\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m dtypes]\n\u001b[1;32m---> 58\u001b[0m common \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfind_common_type(numpy_dtypes, [])\n\u001b[0;32m     59\u001b[0m common \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(tf, common\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m common:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\foolbox_evasion\\Lib\\site-packages\\numpy\\__init__.py:413\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    414\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     )\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchararray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    420\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.chararray` is deprecated and will be removed from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe main namespace in the future. Use an array with a string \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor bytes dtype instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: `np.find_common_type` was removed in the NumPy 2.0 release. Use `numpy.promote_types` or `numpy.result_type` instead. To achieve semantics for the `scalar_types` argument, use `numpy.result_type` and pass the Python values `0`, `0.0`, or `0j`."
     ]
    }
   ],
   "source": [
    "import foolbox as fb\n",
    "import torch\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your trained model (ensure it's a Keras model)\n",
    "model = load_model('Checkpoint_AlexNet_Epoch_50.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "fmodel = fb.TensorFlowModel(model, bounds=(-0.875, 6.96875))  # Ensure bounds match normalization\n",
    "\n",
    "# Define FGSM attack\n",
    "attack = fb.attacks.FGSM()\n",
    "criterion = fb.criteria.Misclassification(tf.convert_to_tensor(y_test_unchanged, dtype=tf.int32))\n",
    "\n",
    "\n",
    "# Set epsilon (perturbation magnitude)\n",
    "epsilon = 0.1\n",
    "\n",
    "X_test_gray_norm_tensor = tf.convert_to_tensor(X_test_gray_norm, dtype=tf.float32)\n",
    "\n",
    "# Generate adversarial examples\n",
    "adversarial_examples, perturbed_images, success = attack(fmodel, X_test_gray_norm_tensor, criterion=criterion, epsilons=epsilon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40cd48-5336-4ca2-9401-a5460b6d13b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python foolbox2",
   "language": "python",
   "name": "foolbox_evasion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
